Using gpu device 0: GeForce GTX TITAN X (CNMeM is enabled with initial size: 20.0% of memory, cuDNN 5103)
WARNING (theano.sandbox.cuda): Ignoring call to use(1), GPU number 0 is already in use.
batch_size = 24
alpha = 0.1
epsilon = 0.0001
activation = T.nnet.relu
num_epochs = 40
LR_start = 0.001
LR_fin = 3e-07
LR_decay = 0.816447063521
shuffle_parts = 1
Loading TCDTIMIT dataset...
Total loaded till now:  0  out of  45000
nbTrainLoaded:  0
nbValidLoaded:  0
nbTestLoaded:  0
loading file /users/start2016/r0364010/TCDTIMIT/database_binary/Lipspkr3.pkl
This dataset contains  14153  images
now loading : nbTrain, nbValid, nbTest
               12030 1415 708
Total loaded till now:  14153  out of  45000
nbTrainLoaded:  12030
nbValidLoaded:  1415
nbTestLoaded:  708
memory consumption (MB) of given matrix:  173
memory consumption (MB) after cast to float:  692
memory consumption (MB) of given matrix:  20
memory consumption (MB) after cast to float:  81
memory consumption (MB) of given matrix:  10
memory consumption (MB) after cast to float:  40
the number of training examples is:  12030
the number of valid examples is:  1415
the number of test examples is:  708
Building the CNN...
Training...
starting training for  40  epochs...
epoch  1 started...
Epoch 1 of 40 took 48.761551857s
  LR:                            0.001
  training loss:                 0.126423339287
  validation loss:               0.0878229385306
  validation error rate:         74.2097701492%
  best epoch:                    1
  best validation error rate:    74.2097701492%
  test loss:                     0.0888587015456
  test error rate:               72.8448275862%
epoch  2 started...
Epoch 2 of 40 took 52.7566878796s
  LR:                            0.000816447063521
  training loss:                 0.0838288309911
  validation loss:               0.084342908628
  validation error rate:         67.5287354095%
  best epoch:                    2
  best validation error rate:    67.5287354095%
  test loss:                     0.084750483519
  test error rate:               65.6609203281%
epoch  3 started...
Epoch 3 of 40 took 54.479321003s
  LR:                            0.000666585807533
  training loss:                 0.0794382192745
  validation loss:               0.0835762622541
  validation error rate:         67.241379259%
  best epoch:                    3
  best validation error rate:    67.241379259%
  test loss:                     0.0819661624987
  test error rate:               63.3620690683%
epoch  4 started...
Epoch 4 of 40 took 55.519523859s
  LR:                            0.000544232025145
  training loss:                 0.0763150085351
  validation loss:               0.0795724493419
  validation error rate:         60.7758620176%
  best epoch:                    4
  best validation error rate:    60.7758620176%
  test loss:                     0.0796020182556
  test error rate:               62.643678435%
epoch  5 started...
Epoch 5 of 40 took 56.0000598431s
  LR:                            0.000444336638804
  training loss:                 0.0730095187243
  validation loss:               0.0789652627347
  validation error rate:         59.626437107%
  best epoch:                    5
  best validation error rate:    59.626437107%
  test loss:                     0.0781687521215
  test error rate:               58.0459771485%
epoch  6 started...
Epoch 6 of 40 took 56.4970180988s
  LR:                            0.000362777343966
  training loss:                 0.069843376416
  validation loss:               0.0793948614135
  validation error rate:         58.6206897579%
  best epoch:                    6
  best validation error rate:    58.6206897579%
  test loss:                     0.0787528460396
  test error rate:               58.1896551724%
epoch  7 started...
Epoch 7 of 40 took 56.5412790775s
  LR:                            0.000296188497193
  training loss:                 0.0664402657967
  validation loss:               0.0785523070472
  validation error rate:         56.5373568185%
  best epoch:                    7
  best validation error rate:    56.5373568185%
  test loss:                     0.0756988999402
  test error rate:               55.4597696354%
epoch  8 started...
Epoch 8 of 40 took 56.6493420601s
  LR:                            0.000241822228782
  training loss:                 0.0629693455697
  validation loss:               0.0788589583003
  validation error rate:         55.1724137417%
  best epoch:                    8
  best validation error rate:    55.1724137417%
  test loss:                     0.0778313288144
  test error rate:               57.7586208952%
epoch  9 started...
Epoch 9 of 40 took 55.5778210163s
  LR:                            0.000197435048583
  training loss:                 0.0585974337024
  validation loss:               0.07955912552
  validation error rate:         56.824712558%
  best epoch:                    8
  best validation error rate:    55.1724137417%
  test loss:                     0.0778313288144
  test error rate:               57.7586208952%
epoch  10 started...
Epoch 10 of 40 took 55.715255022s
  LR:                            0.000161195265652
  training loss:                 0.0544411231747
  validation loss:               0.0815091837711
  validation error rate:         55.8189657228%
  best epoch:                    8
  best validation error rate:    55.1724137417%
  test loss:                     0.0778313288144
  test error rate:               57.7586208952%
epoch  11 started...
Epoch 11 of 40 took 55.6580040455s
  LR:                            0.000131607401295
  training loss:                 0.0495315212496
  validation loss:               0.0864338184996
  validation error rate:         56.5373561506%
  best epoch:                    8
  best validation error rate:    55.1724137417%
  test loss:                     0.0778313288144
  test error rate:               57.7586208952%
epoch  12 started...
Epoch 12 of 40 took 55.9000911713s
  LR:                            0.000107450476325
  training loss:                 0.0447712751355
  validation loss:               0.0902534477927
  validation error rate:         55.3160920739%
  best epoch:                    8
  best validation error rate:    55.1724137417%
  test loss:                     0.0778313288144
  test error rate:               57.7586208952%
epoch  13 started...
Epoch 13 of 40 took 55.7805221081s
  LR:                            8.77276258697e-05
  training loss:                 0.0400459303441
  validation loss:               0.0937258182415
  validation error rate:         55.459770252%
  best epoch:                    8
  best validation error rate:    55.1724137417%
  test loss:                     0.0778313288144
  test error rate:               57.7586208952%
epoch  14 started...
Epoch 14 of 40 took 55.857665062s
  LR:                            7.1624962531e-05
  training loss:                 0.0355483258028
  validation loss:               0.0978572863186
  validation error rate:         55.2442529078%
  best epoch:                    8
  best validation error rate:    55.1724137417%
  test loss:                     0.0778313288144
  test error rate:               57.7586208952%
epoch  15 started...
Epoch 15 of 40 took 55.8171460629s
  LR:                            5.84779903332e-05
  training loss:                 0.0315642386801
  validation loss:               0.101513755476
  validation error rate:         55.459770252%
  best epoch:                    8
  best validation error rate:    55.1724137417%
  test loss:                     0.0778313288144
  test error rate:               57.7586208952%
epoch  16 started...
Epoch 16 of 40 took 55.8704588413s
  LR:                            4.77441834882e-05
  training loss:                 0.0280133665682
  validation loss:               0.10605755975
  validation error rate:         55.316091817%
  best epoch:                    8
  best validation error rate:    55.1724137417%
  test loss:                     0.0778313288144
  test error rate:               57.7586208952%
epoch  17 started...
Epoch 17 of 40 took 55.6803469658s
  LR:                            3.89805984092e-05
  training loss:                 0.0249999578793
  validation loss:               0.110698521137
  validation error rate:         56.8965519297%
  best epoch:                    8
  best validation error rate:    55.1724137417%
  test loss:                     0.0778313288144
  test error rate:               57.7586208952%
epoch  18 started...
Epoch 18 of 40 took 56.9346120358s
  LR:                            3.18255951055e-05
  training loss:                 0.0224534644877
  validation loss:               0.112528739561
  validation error rate:         55.1005748839%
  best epoch:                    18
  best validation error rate:    55.1005748839%
  test loss:                     0.105705739609
  test error rate:               57.3275865152%
epoch  19 started...
Epoch 19 of 40 took 55.8105680943s
  LR:                            2.59839136687e-05
  training loss:                 0.0206208443065
  validation loss:               0.115527511799
  validation error rate:         56.1063221303%
  best epoch:                    18
  best validation error rate:    55.1005748839%
  test loss:                     0.105705739609
  test error rate:               57.3275865152%
epoch  20 started...
Epoch 20 of 40 took 55.6768391132s
  LR:                            2.12144900136e-05
  training loss:                 0.0185815313006
  validation loss:               0.119723618416
  validation error rate:         57.2557475546%
  best epoch:                    18
  best validation error rate:    55.1005748839%
  test loss:                     0.105705739609
  test error rate:               57.3275865152%
epoch  21 started...
Epoch 21 of 40 took 55.8159630299s
  LR:                            1.73205080757e-05
  training loss:                 0.0174437612239
  validation loss:               0.121931404004
  validation error rate:         56.4655173955%
  best epoch:                    18
  best validation error rate:    55.1005748839%
  test loss:                     0.105705739609
  test error rate:               57.3275865152%

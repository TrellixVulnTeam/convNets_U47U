
@Book{h2g2,
  author = 	 {Adams, Douglas},
  title = 	 {The Hitchhiker's Guide to the Galaxy},
  publisher = 	 {Del Rey (reprint)},
  year = 	 1995,
  number =       {ISBN-13: 978-0345391803},
  annote = 	 {Ik weet dat dit niet de originele uitgever en uitgifte datum is}}


@Book{pratchett06:_good_omens,
  author = 	 {Pratchett, Terry and Gaiman, Neil},
  title = 	 {Good Omens: \emph{The Nice and Accurate Prophecies of Agnes Nutter, Witch}},
  publisher = 	 {HarperTorch (reprint)},
  year = 	 2006,
  number = 	 {ISBN-13: 978-0060853983}}

@electronic{wiki,
title = {Proefschrift},
url = {http://nl.wikipedia.org/wiki/Proefschrift},
note = {last checked: 5/3/2007}
}

##########################
####    LIP READING   ####
##########################

@misc{stanfordCS231n,
    title = {CS231n: Convolutional Neural Networks for Visual Recognition},
    howpublished = {\url{http://cs231n.stanford.edu/}},
    note = {Accessed: 2016-11-27}
}


@article{lipnet_assael2016,
    title={LipNet: Sentence-level Lipreading},
    author={Assael, Yannis M and Shillingford, Brendan and Whiteson, Shimon and de Freitas, Nando},
    journal={arXiv preprint arXiv:1611.01599},
    year={2016}
}

lipreading with LSTM
@inproceedings{wand2016lipreading,
    title={Lipreading with long short-term memory},
    author={Wand, Michael and Koutn{\'\i}k, Jan and Schmidhuber, J{\"u}rgen},
    booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE International Conference on},
    pages={6115--6119},
    year={2016},
    organization={IEEE}
}

Combination CNN, LSTM
@techreport{garg2016lip,
    title={Lip reading using CNN and LSTM},
    author={Garg, Amit and Noyola, Jonathan and Bagadia, Sameep},
    year={2016},
    institution={Technical report, Stanford University, CS231n project report}
}

First CNN paper
@inproceedings{imagenet_krizhevsky2012,
    title={Imagenet classification with deep convolutional neural networks},
    author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
    booktitle={Advances in neural information processing systems},
    pages={1097--1105},
    year={2012}
}

Dropout
@article{srivastava2014dropout,
    title={Dropout: a simple way to prevent neural networks from overfitting.},
    author={Srivastava, Nitish and Hinton, Geoffrey E and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
    journal={Journal of Machine Learning Research},
    volume={15},
    number={1},
    pages={1929--1958},
    year={2014}
}

ResNets
@inproceedings{he2016deep,
    title={Deep residual learning for image recognition},
    author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
    booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
    pages={770--778},
    year={2016}
}

Speaker adaptive lipreading
@inproceedings{almajai2016improved,
    title={Improved speaker independent lip reading using speaker adaptive training and deep neural networks},
    author={Almajai, Ibrahim and Cox, Stephen and Harvey, Richard and Lan, Yuxuan},
    booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE International Conference on},
    pages={2722--2726},
    year={2016},
    organization={IEEE}
}

Oxford, Google WLAS  (see bottom)
article{WLAS2016,
    title={Lip reading sentences in the wild},
    author={Chung, Joon Son and Senior, Andrew and Vinyals, Oriol and Zisserman, Andrew},
    journal={arXiv preprint arXiv:1611.05358},
    year={2016}
}

Phoneme- to -Viseme mapping
@inproceedings{cappelletta2012phoneme,
    title={Phoneme-to-viseme Mapping for Visual Speech Recognition.},
    author={Cappelletta, Luca and Harte, Naomi},
    booktitle={ICPRAM (2)},
    pages={322--329},
    year={2012}
}
#######################
####   AUDIO SR    ####
#######################

Stanford course on Natural Language Processing (NLP)
@misc{stanfordCS224d,
    title = {CS224d: Deep Learning for Natural Language Processing},
    howpublished = {\url{http://cs224d.stanford.edu/}},
note = {Accessed: 2017-10-03}
}

Background
--------------
@article{hochreiter1997long,
    title={Long short-term memory},
    author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
    journal={Neural computation},
    volume={9},
    number={8},
    pages={1735--1780},
    year={1997},
    publisher={MIT Press}
}

Schmidhuber & Graves: Bidirectional LSTM
@inproceedings{BiLSTMGraves,
    title={Bidirectional LSTM networks for improved phoneme classification and recognition},
    author={Graves, Alex and Fern{\'a}ndez, Santiago and Schmidhuber, J{\"u}rgen},
    booktitle={International Conference on Artificial Neural Networks},
    pages={799--804},
    year={2005},
    organization={Springer}
}

@ARTICLE{BiLSTMGraves2,
    author = {Alex Graves and JÃ¼rgen Schmidhuber},
    title = {Framewise phoneme classification with bidirectional lstm and other neural network architectures},
    journal = {Neural Networks},
    year = {2005},
    pages = {5--6}
}

@article{BiLSTM_TIMIT,
    title={Phoneme recognition in TIMIT with BLSTM-CTC},
    author={Fern{\'a}ndez, Santiago and Graves, Alex and Schmidhuber, J{\"u}rgen},
    journal={arXiv preprint arXiv:0804.3269},
    year={2008}
}

# GRU vs LSTM
@article{DBLP:journals/corr/ChungGCB14,
    author    = {Junyoung Chung and
    {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
    KyungHyun Cho and
    Yoshua Bengio},
    title     = {Empirical Evaluation of Gated Recurrent Neural Networks on Sequence
    Modeling},
    journal   = {CoRR},
    volume    = {abs/1412.3555},
    year      = {2014},
    url       = {http://arxiv.org/abs/1412.3555},
    timestamp = {Thu, 01 Jan 2015 19:51:08 +0100},
    biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/ChungGCB14},
    bibsource = {dblp computer science bibliography, http://dblp.org}
}

# Deep recurrent neural networks
@inproceedings{graves2013_DRNNspeech,
    title={Speech recognition with deep recurrent neural networks},
    author={Graves, Alex and Mohamed, Abdel-rahman and Hinton, Geoffrey},
    booktitle={Acoustics, speech and signal processing (icassp), 2013 ieee international conference on},
    pages={6645--6649},
    year={2013},
    organization={IEEE}
}

Raw speech, no MFCC as input
-------------------------------
@techreport{palaz2015analysis,
    title={Analysis of cnn-based speech recognition system using raw speech as input},
    author={Palaz, Dimitri and Collobert, Ronan and others},
    year={2015},
    institution={Idiap}
}

Mixing LSTM and CNN
---------------------
Combining CNN, LSTM, DNN in one network for speech
@inproceedings{sainath2015convolutional,
    title={Convolutional, long short-term memory, fully connected deep neural networks},
    author={Sainath, Tara N and Vinyals, Oriol and Senior, Andrew and Sak, Ha{\c{s}}im},
    booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on},
    pages={4580--4584},
    year={2015},
    organization={IEEE}
}

@article{geras2015blending,
    title={Blending LSTMs into CNNs},
    author={Geras, Krzysztof J and Mohamed, Abdel-rahman and Caruana, Rich and Urban, Gregor and Wang, Shengjie and Aslan, Ozlem and Philipose, Matthai and Richardson, Matthew and Sutton, Charles},
    journal={arXiv preprint arXiv:1511.06433},
    year={2015}
}


End To End
----------------
Stanford CNN + CTC RNN
@techreport{EndToEndSong2015,
    title={End-to-end deep neural network for automatic speech recognition},
    author={Song, William and Cai, Jim},
    year={2015},
    institution={Technical Report CS224D, University of Stanford}
}

graves
@inproceedings{EndToEndGraves2014,
    title={Towards End-To-End Speech Recognition with Recurrent Neural Networks.},
    author={Graves, Alex and Jaitly, Navdeep},
    booktitle={ICML},
    volume={14},
    pages={1764--1772},
    year={2014}
}

Microsoft beating human performance with Deep nets (VGG, ResNet)
@article{MicrosoftXiong2016achieving,
    title={Achieving human parity in conversational speech recognition},
    author={Xiong, Wayne and Droppo, Jasha and Huang, Xuedong and Seide, Frank and Seltzer, Mike and Stolcke, Andreas and Yu, Dong and Zweig, Geoffrey},
    journal={arXiv preprint arXiv:1610.05256},
    year={2016}
}

Baidu
@article{amodei2015deep,
    title={Deep speech 2: End-to-end speech recognition in english and mandarin},
    author={Amodei, Dario and Anubhai, Rishita and Battenberg, Eric and Case, Carl and Casper, Jared and Catanzaro, Bryan and Chen, Jingdong and Chrzanowski, Mike and Coates, Adam and Diamos, Greg and others},
    journal={arXiv preprint arXiv:1512.02595},
    year={2015}
}

Older techniques
-------------------
@inproceedings{sugiyama1991review,
    title={Review of TDNN (Time Delay Neural Network) architectures for speech recognition},
    author={Sugiyama, Masahide and Sawai, Hidehumi and Waibel, Alexander H},
    booktitle={Circuits and Systems, 1991., IEEE International Sympoisum on},
    pages={582--585},
    year={1991},
    organization={IEEE}
}


########################
####  INTEGRATION    ###
########################
@inproceedings{goecke2006audio,
    title={Audio-video automatic speech recognition: an example of improved performance through multimodal sensor input},
    author={Goecke, Roland},
    booktitle={Proceedings of the 2005 NICTA-HCSNet Multimodal User Interaction Workshop-Volume 57},
    pages={25--32},
    year={2006},
    organization={Australian Computer Society, Inc.}
}

@article{makkook2007multimodal,
    title={A multimodal sensor fusion architecture for audio-visual speech recognition},
    author={Makkook, Mustapha},
    year={2007},
    publisher={University of Waterloo}
}

@inproceedings{seeMeHearMe,
    title={See me, hear me: integrating automatic speech recognition and lip-reading.},
    author={Duchnowski, Paul and Meier, Uwe and Waibel, Alex},
    booktitle={ICSLP},
    volume={94},
    pages={547--550},
    year={1994},
    organization={Citeseer}
}

Oxford, Google WLAS
@article{WLAS2016,
    title={Lip reading sentences in the wild},
    author={Chung, Joon Son and Senior, Andrew and Vinyals, Oriol and Zisserman, Andrew},
    journal={arXiv preprint arXiv:1611.05358},
    year={2016}
}


###################
### BACKGROUND  ###
###################

Deep Learning Overview
@article{888, 
    author = "J. Schmidhuber", 
    title = "Deep Learning in Neural Networks: An Overview", 
    journal = "Neural Networks", 
    pages = "85-117", 
    volume = "61", 
    doi = "10.1016/j.neunet.2014.09.003", 
    note = "Published online 2014; based on TR arXiv:1404.7828 [cs.NE]", 
    year = "2015"}

LeCun, promo for Deep Networks
@article{bengio2007scaling,
    title={Scaling learning algorithms towards AI},
    author={Bengio, Yoshua and LeCun, Yann and others},
    journal={Large-scale kernel machines},
    volume={34},
    number={5},
    pages={1--41},
    year={2007}
}

backprop
@incollection{lecun2012efficient,
    title={Efficient backprop},
    author={LeCun, Yann A and Bottou, L{\'e}on and Orr, Genevieve B and M{\"u}ller, Klaus-Robert},
    booktitle={Neural networks: Tricks of the trade},
    pages={9--48},
    year={2012},
    publisher={Springer}
}

#################
### DATASET  ####
#################
TCD-TIMIT
@article{harte2015tcd,
    title={TCD-TIMIT: An audio-visual corpus of continuous speech},
    author={Harte, Naomi and Gillen, Eoin},
    journal={IEEE Transactions on Multimedia},
    volume={17},
    number={5},
    pages={603--615},
    year={2015},
    publisher={IEEE}
}

more extensive: E. Gillen thesis
@article{harte2015tcd,
    title={TCD-TIMIT: An audio-visual corpus of continuous speech},
    author={Harte, Naomi and Gillen, Eoin},
    journal={IEEE Transactions on Multimedia},
    volume={17},
    number={5},
    pages={603--615},
    year={2015},
    publisher={IEEE}
}

older dataset comparison
@article{chictu2007building,
    title={Building a data corpus for audio-visual speech recognition},
    author={Chi{\c{t}}u, Alin G and Rothkrantz, Leon JM},
    journal={Proceedings of Euromedia2007},
    pages={88--92},
    year={2007}
}

TIMIT dataset
@article{garofolo1993darpa,
    title={DARPA TIMIT acoustic-phonetic continous speech corpus},
    author={Garofolo, John S and Lamel, Lori F and Fisher, William M and Fiscus, Jonathon G and Pallett, David S},
    journal={NASA STI/Recon technical report n},
    volume={93},
    year={1993}
}